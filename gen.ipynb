{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designations:sde,sde sr,solutions enabler, consultant, solutions architect,principal architect,it ,finance, accounting,hr  \n",
    "skills:java, java swing, sql, c,c#,c++,go, django, html,css, javascript, node.js, next.js,typescript,python,devops,machine learning, data analysis,dbt,snowflake,azure,powerbi,data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faker pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ananyasarkar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Users: 100%|██████████| 10/10 [00:00<00:00, 21.73user/s]\n",
      "Generating Courses: 100%|██████████| 30/30 [00:00<00:00, 14988.58course/s]\n",
      "Generating Initial Progress: 100%|██████████| 300/300 [00:03<00:00, 92.70user/s]\n",
      "Simulating Progress Updates: 100%|██████████| 300/300 [00:08<00:00, 35.53user/s]\n",
      "Generating User Skills: 100%|██████████| 300/300 [00:00<00:00, 100094.76user/s]\n",
      "Generating Course Skills: 100%|██████████| 30/30 [00:00<00:00, 29966.45course/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation completed and files saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Provided designations, skills, and course names\n",
    "designations = [\n",
    "    'SDE', 'SDE Sr', 'Solutions Enabler', 'Consultant',\n",
    "    'Solutions Architect', 'Principal Architect', 'IT',\n",
    "    'Finance', 'Accounting', 'HR'\n",
    "]\n",
    "\n",
    "skills = [\n",
    "    'Java', 'Java Swing', 'SQL', 'C', 'C#', 'C++',\n",
    "    'Go', 'Django', 'HTML', 'CSS', 'JavaScript',\n",
    "    'Node.js', 'Next.js', 'TypeScript', 'Python',\n",
    "    'DevOps', 'Machine Learning', 'Data Analysis',\n",
    "    'DBT', 'Snowflake', 'Azure', 'PowerBI',\n",
    "    'Data Structures', 'Cloud Computing', 'Cybersecurity',\n",
    "    'Networking Fundamentals', 'Agile Methodologies',\n",
    "    'Employee Relations', 'Performance Management',\n",
    "    'Recruitment and Selection', 'HR Information Systems (HRIS)',\n",
    "    'Conflict Resolution'\n",
    "]\n",
    "\n",
    "course_names = [\n",
    "    \"Java Programming Essentials\", \"Mastering Java Swing for Desktop Applications\",\n",
    "    \"SQL for Data Management\", \"C Programming for Beginners\",\n",
    "    \"Advanced C# Techniques\", \"C++ for Game Development\",\n",
    "    \"Go: A Comprehensive Guide\", \"Building Web Applications with Django\",\n",
    "    \"HTML & CSS: The Complete Guide\", \"JavaScript Fundamentals\",\n",
    "    \"Node.js for Scalable Network Applications\",\n",
    "    \"Next.js: Server-Side Rendering Made Easy\",\n",
    "    \"TypeScript for Large Applications\", \"Python for Data Analysis\",\n",
    "    \"DevOps Fundamentals: Continuous Integration & Delivery\",\n",
    "    \"Machine Learning with Python\", \"Data Analysis Techniques for Business Insights\",\n",
    "    \"DBT: Transforming Data in the Warehouse\", \"Snowflake Essentials: Data Warehousing\",\n",
    "    \"Azure Cloud Fundamentals\", \"Power BI for Data Visualization\",\n",
    "    \"Data Structures and Algorithms in Java\", \"Cloud Security: Best Practices for IT\",\n",
    "    \"HR Analytics: Leveraging Data for HR Decisions\",\n",
    "    \"IT Project Management Fundamentals\",\n",
    "    \"Agile Methodologies for HR and IT\",\n",
    "    \"Cybersecurity Essentials for IT Professionals\",\n",
    "    \"Effective Communication in HR\",\n",
    "    \"Talent Management Strategies in the Digital Age\",\n",
    "    \"Building a Diverse Workplace Culture\"\n",
    "]\n",
    "\n",
    "# Constants for the fake data generation\n",
    "NUM_USERS = 300\n",
    "NUM_COURSES = len(course_names)\n",
    "\n",
    "# User distribution based on your specifications\n",
    "user_distribution = {\n",
    "    'SDE': 100,\n",
    "    'SDE Sr': 70,\n",
    "    'Solutions Enabler': 45,\n",
    "    'Consultant': 40,\n",
    "    'Solutions Architect': 30,\n",
    "    'Principal Architect': 15,\n",
    "    'IT': 55,\n",
    "    'Finance': 70,\n",
    "    'Accounting': 60,\n",
    "    'HR': 15\n",
    "}\n",
    "\n",
    "# Generate Designations\n",
    "designations_df = pd.DataFrame({'id': range(1, len(designations) + 1), 'title': designations})\n",
    "\n",
    "# Generate Skills\n",
    "skills_df = pd.DataFrame({'id': range(1, len(skills) + 1), 'name': skills})\n",
    "\n",
    "# Generate Users\n",
    "users = []\n",
    "user_id = 1\n",
    "\n",
    "for designation, count in tqdm(user_distribution.items(), desc=\"Generating Users\", unit=\"user\"):\n",
    "    for _ in range(count):\n",
    "        users.append({\n",
    "            'id': user_id,\n",
    "            'name': fake.name(),\n",
    "            'mail': fake.unique.email(),\n",
    "            'role': 'employee',  # All users are employees\n",
    "            'designationId': designations_df[designations_df['title'] == designation]['id'].values[0],\n",
    "            'sex': random.choice(['m', 'f']),\n",
    "            'experience': random.randint(0, 20),  # Experience in years\n",
    "            'joindate': fake.date_between(start_date='-8y', end_date='today'),\n",
    "            'hashedpassword': fake.password()\n",
    "        })\n",
    "        user_id += 1\n",
    "\n",
    "users_df = pd.DataFrame(users)\n",
    "\n",
    "# Ensure join date is a datetime object\n",
    "users_df['joindate'] = pd.to_datetime(users_df['joindate'])\n",
    "\n",
    "# Generate Courses\n",
    "courses = []\n",
    "for i in tqdm(range(1, NUM_COURSES + 1), desc=\"Generating Courses\", unit=\"course\"):\n",
    "    created_at = fake.date_time_this_decade()\n",
    "    courses.append({\n",
    "        'id': i,\n",
    "        'title': course_names[i - 1],\n",
    "        'proficiency_level': random.choice(['Beginner', 'Intermediate', 'Advanced']),\n",
    "        'no_of_chapters': random.randint(5, 20),  # Random total chapters\n",
    "        'duration': random.randint(2, 10),  # Duration in days\n",
    "        'createdAt': created_at\n",
    "    })\n",
    "courses_df = pd.DataFrame(courses)\n",
    "\n",
    "# Ensure date columns are datetime\n",
    "courses_df['createdAt'] = pd.to_datetime(courses_df['createdAt'])\n",
    "\n",
    "# Generate Initial Progress with 0 chapters completed\n",
    "initial_progress = []\n",
    "for user_id in tqdm(range(1, NUM_USERS + 1), desc=\"Generating Initial Progress\", unit=\"user\"):\n",
    "    for course_id in range(1, NUM_COURSES + 1):\n",
    "        initial_progress.append({\n",
    "            'id': len(initial_progress) + 1,\n",
    "            'courseId': course_id,\n",
    "            'userId': user_id,\n",
    "            'updatedAt': courses_df.loc[courses_df['id'] == course_id, 'createdAt'].values[0],  # Set to creation date\n",
    "            'chapters_completed': 0,\n",
    "            'percentage_completed': 0.0,\n",
    "            'certificate': None  # Nullable field\n",
    "        })\n",
    "\n",
    "# Simulate Progress Updates\n",
    "progress_updates = []\n",
    "for user_id in tqdm(range(1, NUM_USERS + 1), desc=\"Simulating Progress Updates\", unit=\"user\"):\n",
    "    user_join_date = users_df.loc[users_df['id'] == user_id, 'joindate'].values[0]\n",
    "    completed_courses = []\n",
    "\n",
    "    for course_id in range(1, NUM_COURSES + 1):\n",
    "        if course_id in completed_courses:\n",
    "            continue  # Skip if the course is already completed\n",
    "\n",
    "        total_chapters = courses_df.loc[courses_df['id'] == course_id, 'no_of_chapters'].values[0]\n",
    "        creation_date = courses_df.loc[courses_df['id'] == course_id, 'createdAt'].values[0]\n",
    "\n",
    "        # Ensure both dates are datetime\n",
    "        creation_date = pd.to_datetime(creation_date)\n",
    "        user_join_date = pd.to_datetime(user_join_date)\n",
    "\n",
    "        # Simulate a few updates over time\n",
    "        for update in range(random.randint(1, 5)):  # Randomly generate 1 to 5 progress updates\n",
    "            chapters_completed = random.randint(1, total_chapters)  # Randomly increase chapters completed\n",
    "            chapters_completed = min(chapters_completed, total_chapters)\n",
    "            percentage_completed = (chapters_completed / total_chapters) * 100\n",
    "\n",
    "            # Random time increment for each update, ensuring it's after both dates\n",
    "            update_time = max(\n",
    "                creation_date + timedelta(days=update * random.randint(1, 20)),  # Ensure no more than 20 days apart\n",
    "                user_join_date + timedelta(days=random.randint(0, 30))  # Adding random days after join date\n",
    "            )\n",
    "\n",
    "            progress_updates.append({\n",
    "                'id': len(progress_updates) + 1,\n",
    "                'courseId': course_id,\n",
    "                'userId': user_id,\n",
    "                'updatedAt': update_time,\n",
    "                'chapters_completed': chapters_completed,\n",
    "                'percentage_completed': percentage_completed,\n",
    "                'certificate': fake.file_name(extension='pdf') if percentage_completed == 100 else None  # Nullable field\n",
    "            })\n",
    "\n",
    "            if percentage_completed == 100:\n",
    "                completed_courses.append(course_id)  # Mark course as completed\n",
    "\n",
    "# Combine initial progress with updates\n",
    "all_progress = initial_progress + progress_updates\n",
    "\n",
    "# Convert to DataFrame\n",
    "progress_df = pd.DataFrame(all_progress)\n",
    "\n",
    "# Generate User Skill Proficiency\n",
    "user_skills = []\n",
    "for user_id in tqdm(range(1, NUM_USERS + 1), desc=\"Generating User Skills\", unit=\"user\"):\n",
    "    for skill_id in random.sample(range(1, len(skills) + 1), k=random.randint(1, 5)):\n",
    "        user_skills.append({\n",
    "            'id': len(user_skills) + 1,\n",
    "            'userId': user_id,\n",
    "            'skillId': skill_id,\n",
    "            'Proficiency_level': random.choice(['Beginner', 'Intermediate', 'Advanced'])\n",
    "        })\n",
    "user_skills_df = pd.DataFrame(user_skills)\n",
    "\n",
    "# Generate Course Skills\n",
    "course_skills = []\n",
    "for course_id in tqdm(range(1, NUM_COURSES + 1), desc=\"Generating Course Skills\", unit=\"course\"):\n",
    "    for skill_id in random.sample(range(1, len(skills) + 1), k=random.randint(1, 5)):\n",
    "        course_skills.append({\n",
    "            'id': len(course_skills) + 1,\n",
    "            'courseId': course_id,\n",
    "            'skillId': skill_id,\n",
    "        })\n",
    "course_skills_df = pd.DataFrame(course_skills)\n",
    "\n",
    "# Save to CSV files\n",
    "save_path = r'C:\\Users\\AnanyaSarkar\\Documents\\project\\datascienceandengg\\staging\\raw\\\\'\n",
    "\n",
    "users_df.to_csv(f'{save_path}users.csv', index=False)\n",
    "courses_df.to_csv(f'{save_path}courses.csv', index=False)\n",
    "designations_df.to_csv(f'{save_path}designations.csv', index=False)\n",
    "skills_df.to_csv(f'{save_path}skills.csv', index=False)\n",
    "progress_df.to_csv(f'{save_path}progress.csv', index=False)\n",
    "user_skills_df.to_csv(f'{save_path}user_skills.csv', index=False)\n",
    "course_skills_df.to_csv(f'{save_path}course_skills.csv', index=False)\n",
    "\n",
    "print(\"Data generation completed and files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for progress i want to show progress updates of employees in various courses they have been enrolled in . the user will always start with 0 'chapters_completed' , and will progress. it will be a timeseries data which means it wont overwrite the previous progressupdate. i dont need 100 as the end of every course for every employee but 0for every course for every employee is necessary. and the 'percentage_completed' is calculated by 'chapters_completed'*100/'total chapters' in that course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Skills and Designations data\n",
    "skills_data = [\n",
    "    (1, 'Java'),\n",
    "    (2, 'Java Swing'),\n",
    "    (3, 'SQL'),\n",
    "    (4, 'C'),\n",
    "    (5, 'C#'),\n",
    "    (6, 'C++'),\n",
    "    (7, 'Go'),\n",
    "    (8, 'Django'),\n",
    "    (9, 'HTML'),\n",
    "    (10, 'CSS'),\n",
    "    (11, 'JavaScript'),\n",
    "    (12, 'Node.js'),\n",
    "    (13, 'Next.js'),\n",
    "    (14, 'TypeScript'),\n",
    "    (15, 'Python'),\n",
    "    (16, 'DevOps'),\n",
    "    (17, 'Machine Learning'),\n",
    "    (18, 'Data Analysis'),\n",
    "    (19, 'DBT'),\n",
    "    (20, 'Snowflake'),\n",
    "    (21, 'Azure'),\n",
    "    (22, 'PowerBI'),\n",
    "    (23, 'Data Structures'),\n",
    "    (24, 'Cloud Computing'),\n",
    "    (25, 'Cybersecurity'),\n",
    "    (26, 'Networking Fundamentals'),\n",
    "    (27, 'Agile Methodologies'),\n",
    "    (28, 'Employee Relations'),\n",
    "    (29, 'Performance Management'),\n",
    "    (30, 'Recruitment and Selection'),\n",
    "    (31, 'HR Information Systems (HRIS)'),\n",
    "    (32, 'Conflict Resolution'),\n",
    "]\n",
    "\n",
    "designations_data = [\n",
    "    (1, 'SDE'),\n",
    "    (2, 'SDE Sr'),\n",
    "    (3, 'Solutions Enabler'),\n",
    "    (4, 'Consultant'),\n",
    "    (5, 'Solutions Architect'),\n",
    "    (6, 'Principal Architect'),\n",
    "    (7, 'IT'),\n",
    "    (8, 'Finance'),\n",
    "    (9, 'Accounting'),\n",
    "    (10, 'HR'),\n",
    "]\n",
    "\n",
    "# Create DataFrames for skills and designations\n",
    "skills_df = pd.DataFrame(skills_data, columns=['id', 'name'])\n",
    "designations_df = pd.DataFrame(designations_data, columns=['id', 'title'])\n",
    "\n",
    "# Define the skills needed for each designation (you can customize this as needed)\n",
    "designations_skills = [\n",
    "    (1, 1), (1, 3), (1, 15),  # SDE: Java, SQL, Python\n",
    "    (2, 1), (2, 3), (2, 15), (2, 16),  # SDE Sr: Java, SQL, Python, DevOps\n",
    "    (3, 8), (3, 17), (3, 18),  # Solutions Enabler: HTML, Machine Learning, Data Analysis\n",
    "    (4, 3), (4, 9), (4, 18),  # Consultant: SQL, HTML, Data Analysis\n",
    "    (5, 15), (5, 19), (5, 21),  # Solutions Architect: Python, DBT, Azure\n",
    "    (6, 20), (6, 22), (6, 25),  # Principal Architect: Snowflake, PowerBI, Cybersecurity\n",
    "    (7, 27), (7, 28),  # IT: Agile Methodologies, Employee Relations\n",
    "    (8, 29), (8, 31),  # Finance: Performance Management, HRIS\n",
    "    (9, 29), (9, 27),  # Accounting: Performance Management, Agile Methodologies\n",
    "    (10, 28), (10, 30),  # HR: Employee Relations, Recruitment and Selection\n",
    "]\n",
    "\n",
    "# Create DataFrame for designations_skills\n",
    "designations_skills_df = pd.DataFrame(designations_skills, columns=['designation_id', 'skill_id'])\n",
    "\n",
    "# Save to CSV files\n",
    "skills_df.to_csv('C:\\\\Users\\\\AnanyaSarkar\\\\Documents\\\\project\\\\datascienceandengg\\\\staging\\\\raw\\\\skills.csv', index=False)\n",
    "designations_df.to_csv('C:\\\\Users\\\\AnanyaSarkar\\\\Documents\\\\project\\\\datascienceandengg\\\\staging\\\\raw\\\\designations.csv', index=False)\n",
    "designations_skills_df.to_csv('C:\\\\Users\\\\AnanyaSarkar\\\\Documents\\\\project\\\\datascienceandengg\\\\staging\\\\raw\\\\designations_skill.csv', index=False)\n",
    "\n",
    "print(\"CSV files generated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
