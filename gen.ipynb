{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designations:sde,sde sr,solutions enabler, consultant, solutions architect,principal architect,it ,finance, accounting,hr  \n",
    "skills:java, java swing, sql, c,c#,c++,go, django, html,css, javascript, node.js, next.js,typescript,python,devops,machine learning, data analysis,dbt,snowflake,azure,powerbi,data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faker pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ananyasarkar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Users: 100%|██████████| 10/10 [00:00<00:00, 21.73user/s]\n",
      "Generating Courses: 100%|██████████| 30/30 [00:00<00:00, 14988.58course/s]\n",
      "Generating Initial Progress: 100%|██████████| 300/300 [00:03<00:00, 92.70user/s]\n",
      "Simulating Progress Updates: 100%|██████████| 300/300 [00:08<00:00, 35.53user/s]\n",
      "Generating User Skills: 100%|██████████| 300/300 [00:00<00:00, 100094.76user/s]\n",
      "Generating Course Skills: 100%|██████████| 30/30 [00:00<00:00, 29966.45course/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation completed and files saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Provided designations, skills, and course names\n",
    "designations = [\n",
    "    'SDE', 'SDE Sr', 'Solutions Enabler', 'Consultant',\n",
    "    'Solutions Architect', 'Principal Architect', 'IT',\n",
    "    'Finance', 'Accounting', 'HR'\n",
    "]\n",
    "\n",
    "skills = [\n",
    "    'Java', 'Java Swing', 'SQL', 'C', 'C#', 'C++',\n",
    "    'Go', 'Django', 'HTML', 'CSS', 'JavaScript',\n",
    "    'Node.js', 'Next.js', 'TypeScript', 'Python',\n",
    "    'DevOps', 'Machine Learning', 'Data Analysis',\n",
    "    'DBT', 'Snowflake', 'Azure', 'PowerBI',\n",
    "    'Data Structures', 'Cloud Computing', 'Cybersecurity',\n",
    "    'Networking Fundamentals', 'Agile Methodologies',\n",
    "    'Employee Relations', 'Performance Management',\n",
    "    'Recruitment and Selection', 'HR Information Systems (HRIS)',\n",
    "    'Conflict Resolution'\n",
    "]\n",
    "\n",
    "course_names = [\n",
    "    \"Java Programming Essentials\", \"Mastering Java Swing for Desktop Applications\",\n",
    "    \"SQL for Data Management\", \"C Programming for Beginners\",\n",
    "    \"Advanced C# Techniques\", \"C++ for Game Development\",\n",
    "    \"Go: A Comprehensive Guide\", \"Building Web Applications with Django\",\n",
    "    \"HTML & CSS: The Complete Guide\", \"JavaScript Fundamentals\",\n",
    "    \"Node.js for Scalable Network Applications\",\n",
    "    \"Next.js: Server-Side Rendering Made Easy\",\n",
    "    \"TypeScript for Large Applications\", \"Python for Data Analysis\",\n",
    "    \"DevOps Fundamentals: Continuous Integration & Delivery\",\n",
    "    \"Machine Learning with Python\", \"Data Analysis Techniques for Business Insights\",\n",
    "    \"DBT: Transforming Data in the Warehouse\", \"Snowflake Essentials: Data Warehousing\",\n",
    "    \"Azure Cloud Fundamentals\", \"Power BI for Data Visualization\",\n",
    "    \"Data Structures and Algorithms in Java\", \"Cloud Security: Best Practices for IT\",\n",
    "    \"HR Analytics: Leveraging Data for HR Decisions\",\n",
    "    \"IT Project Management Fundamentals\",\n",
    "    \"Agile Methodologies for HR and IT\",\n",
    "    \"Cybersecurity Essentials for IT Professionals\",\n",
    "    \"Effective Communication in HR\",\n",
    "    \"Talent Management Strategies in the Digital Age\",\n",
    "    \"Building a Diverse Workplace Culture\"\n",
    "]\n",
    "\n",
    "# Constants for the fake data generation\n",
    "NUM_USERS = 300\n",
    "NUM_COURSES = len(course_names)\n",
    "\n",
    "# User distribution based on your specifications\n",
    "user_distribution = {\n",
    "    'SDE': 100,\n",
    "    'SDE Sr': 70,\n",
    "    'Solutions Enabler': 45,\n",
    "    'Consultant': 40,\n",
    "    'Solutions Architect': 30,\n",
    "    'Principal Architect': 15,\n",
    "    'IT': 55,\n",
    "    'Finance': 70,\n",
    "    'Accounting': 60,\n",
    "    'HR': 15\n",
    "}\n",
    "\n",
    "# Generate Designations\n",
    "designations_df = pd.DataFrame({'id': range(1, len(designations) + 1), 'title': designations})\n",
    "\n",
    "# Generate Skills\n",
    "skills_df = pd.DataFrame({'id': range(1, len(skills) + 1), 'name': skills})\n",
    "\n",
    "# Generate Users\n",
    "users = []\n",
    "user_id = 1\n",
    "\n",
    "for designation, count in tqdm(user_distribution.items(), desc=\"Generating Users\", unit=\"user\"):\n",
    "    for _ in range(count):\n",
    "        users.append({\n",
    "            'id': user_id,\n",
    "            'name': fake.name(),\n",
    "            'mail': fake.unique.email(),\n",
    "            'role': 'employee',  # All users are employees\n",
    "            'designationId': designations_df[designations_df['title'] == designation]['id'].values[0],\n",
    "            'sex': random.choice(['m', 'f']),\n",
    "            'experience': random.randint(0, 20),  # Experience in years\n",
    "            'joindate': fake.date_between(start_date='-8y', end_date='today'),\n",
    "            'hashedpassword': fake.password()\n",
    "        })\n",
    "        user_id += 1\n",
    "\n",
    "users_df = pd.DataFrame(users)\n",
    "\n",
    "# Ensure join date is a datetime object\n",
    "users_df['joindate'] = pd.to_datetime(users_df['joindate'])\n",
    "\n",
    "# Generate Courses\n",
    "courses = []\n",
    "for i in tqdm(range(1, NUM_COURSES + 1), desc=\"Generating Courses\", unit=\"course\"):\n",
    "    created_at = fake.date_time_this_decade()\n",
    "    courses.append({\n",
    "        'id': i,\n",
    "        'title': course_names[i - 1],\n",
    "        'proficiency_level': random.choice(['Beginner', 'Intermediate', 'Advanced']),\n",
    "        'no_of_chapters': random.randint(5, 20),  # Random total chapters\n",
    "        'duration': random.randint(2, 10),  # Duration in days\n",
    "        'createdAt': created_at\n",
    "    })\n",
    "courses_df = pd.DataFrame(courses)\n",
    "\n",
    "# Ensure date columns are datetime\n",
    "courses_df['createdAt'] = pd.to_datetime(courses_df['createdAt'])\n",
    "\n",
    "# Generate Initial Progress with 0 chapters completed\n",
    "initial_progress = []\n",
    "for user_id in tqdm(range(1, NUM_USERS + 1), desc=\"Generating Initial Progress\", unit=\"user\"):\n",
    "    for course_id in range(1, NUM_COURSES + 1):\n",
    "        initial_progress.append({\n",
    "            'id': len(initial_progress) + 1,\n",
    "            'courseId': course_id,\n",
    "            'userId': user_id,\n",
    "            'updatedAt': courses_df.loc[courses_df['id'] == course_id, 'createdAt'].values[0],  # Set to creation date\n",
    "            'chapters_completed': 0,\n",
    "            'percentage_completed': 0.0,\n",
    "            'certificate': None  # Nullable field\n",
    "        })\n",
    "\n",
    "# Simulate Progress Updates\n",
    "progress_updates = []\n",
    "for user_id in tqdm(range(1, NUM_USERS + 1), desc=\"Simulating Progress Updates\", unit=\"user\"):\n",
    "    user_join_date = users_df.loc[users_df['id'] == user_id, 'joindate'].values[0]\n",
    "    completed_courses = []\n",
    "\n",
    "    for course_id in range(1, NUM_COURSES + 1):\n",
    "        if course_id in completed_courses:\n",
    "            continue  # Skip if the course is already completed\n",
    "\n",
    "        total_chapters = courses_df.loc[courses_df['id'] == course_id, 'no_of_chapters'].values[0]\n",
    "        creation_date = courses_df.loc[courses_df['id'] == course_id, 'createdAt'].values[0]\n",
    "\n",
    "        # Ensure both dates are datetime\n",
    "        creation_date = pd.to_datetime(creation_date)\n",
    "        user_join_date = pd.to_datetime(user_join_date)\n",
    "\n",
    "        # Simulate a few updates over time\n",
    "        for update in range(random.randint(1, 5)):  # Randomly generate 1 to 5 progress updates\n",
    "            chapters_completed = random.randint(1, total_chapters)  # Randomly increase chapters completed\n",
    "            chapters_completed = min(chapters_completed, total_chapters)\n",
    "            percentage_completed = (chapters_completed / total_chapters) * 100\n",
    "\n",
    "            # Random time increment for each update, ensuring it's after both dates\n",
    "            update_time = max(\n",
    "                creation_date + timedelta(days=update * random.randint(1, 20)),  # Ensure no more than 20 days apart\n",
    "                user_join_date + timedelta(days=random.randint(0, 30))  # Adding random days after join date\n",
    "            )\n",
    "\n",
    "            progress_updates.append({\n",
    "                'id': len(progress_updates) + 1,\n",
    "                'courseId': course_id,\n",
    "                'userId': user_id,\n",
    "                'updatedAt': update_time,\n",
    "                'chapters_completed': chapters_completed,\n",
    "                'percentage_completed': percentage_completed,\n",
    "                'certificate': fake.file_name(extension='pdf') if percentage_completed == 100 else None  # Nullable field\n",
    "            })\n",
    "\n",
    "            if percentage_completed == 100:\n",
    "                completed_courses.append(course_id)  # Mark course as completed\n",
    "\n",
    "# Combine initial progress with updates\n",
    "all_progress = initial_progress + progress_updates\n",
    "\n",
    "# Convert to DataFrame\n",
    "progress_df = pd.DataFrame(all_progress)\n",
    "\n",
    "# Generate User Skill Proficiency\n",
    "user_skills = []\n",
    "for user_id in tqdm(range(1, NUM_USERS + 1), desc=\"Generating User Skills\", unit=\"user\"):\n",
    "    for skill_id in random.sample(range(1, len(skills) + 1), k=random.randint(1, 5)):\n",
    "        user_skills.append({\n",
    "            'id': len(user_skills) + 1,\n",
    "            'userId': user_id,\n",
    "            'skillId': skill_id,\n",
    "            'Proficiency_level': random.choice(['Beginner', 'Intermediate', 'Advanced'])\n",
    "        })\n",
    "user_skills_df = pd.DataFrame(user_skills)\n",
    "\n",
    "# Generate Course Skills\n",
    "course_skills = []\n",
    "for course_id in tqdm(range(1, NUM_COURSES + 1), desc=\"Generating Course Skills\", unit=\"course\"):\n",
    "    for skill_id in random.sample(range(1, len(skills) + 1), k=random.randint(1, 5)):\n",
    "        course_skills.append({\n",
    "            'id': len(course_skills) + 1,\n",
    "            'courseId': course_id,\n",
    "            'skillId': skill_id,\n",
    "        })\n",
    "course_skills_df = pd.DataFrame(course_skills)\n",
    "\n",
    "# Save to CSV files\n",
    "save_path = r'C:\\Users\\AnanyaSarkar\\Documents\\project\\datascienceandengg\\staging\\raw\\\\'\n",
    "\n",
    "users_df.to_csv(f'{save_path}users.csv', index=False)\n",
    "courses_df.to_csv(f'{save_path}courses.csv', index=False)\n",
    "designations_df.to_csv(f'{save_path}designations.csv', index=False)\n",
    "skills_df.to_csv(f'{save_path}skills.csv', index=False)\n",
    "progress_df.to_csv(f'{save_path}progress.csv', index=False)\n",
    "user_skills_df.to_csv(f'{save_path}user_skills.csv', index=False)\n",
    "course_skills_df.to_csv(f'{save_path}course_skills.csv', index=False)\n",
    "\n",
    "print(\"Data generation completed and files saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for progress i want to show progress updates of employees in various courses they have been enrolled in . the user will always start with 0 'chapters_completed' , and will progress. it will be a timeseries data which means it wont overwrite the previous progressupdate. i dont need 100 as the end of every course for every employee but 0for every course for every employee is necessary. and the 'percentage_completed' is calculated by 'chapters_completed'*100/'total chapters' in that course"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
